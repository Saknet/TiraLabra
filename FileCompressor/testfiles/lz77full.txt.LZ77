LZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977[1] and 1978.[2] They are also known as LZ1 and LZ2 respectively.[3] These two$ïform the basis for many variations including LZW, LZSS, LZMA and others. Besides their academic influence, these algorithms formed$~of several ubiquitous compression schemes, including GIF and the DEFLATE algorithm used in PNG.

They are both theoretically dictionary coders. LZ77 maintains a sliding window during$°. This was later shown to be equivalent to the explicit dictionary constructed by LZ78‚Äîhowever, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as$pictionary is available,[dubious ‚Äì discuss] while LZ77 decompression must always start at the beginning of the input.

The algorithms were named an IEEE Milestone in 2004

Theoretical efficiency[edit]
In the second$otwo papers that introduced these algorithms they are analyzed as encoders defined by finite-state machines. A measure analogous to information entropy is developed for individual sequences (as opposed to probabilistic ensembles). This$}	gives a bound on the compression ratio that can be achieved. It is then shown that there exist finite lossless encoders for every sequence that achieve this bound as the length of the$6
grows to infinity. In this sense an algorithm based on this scheme produces asymptotically optimal encodings. This result can be proved more directly, as for example in notes by Peter Shor.[5]

LZ77[edit]
LZ77$Æ
s achieve compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the un$~ed data stream. A match is encoded by a pair of numbers called a length-distance pair, which is equivalent to the statement "each of the next length characters is equal to the characters exactly distanc$behind it in the uncompressed stream". (The "distance" is sometimes called$>"offset" instead.)

To spot matches, the encoder must keep track of some amount of the most recent data, such as the last 2 kB, 4 kB, or 32 kB. The structure in which this data is held is called a sliding window, which is why LZ77 is sometime$8	sliding window compression. The encoder needs to keep this data to look for matches, and the de$=!interpret the matches the encoder refers to. The larger the sliding window is, the longer back$Imay search for creating references.

It is not only acceptable but frequently useful to allow length-distance pairs to specify a length that actually exceeds the distance. As a copy command, this is puzzling: "Go back four characters and copy ten$	rs from that position into the current position". How can ten characters be copied over when only four of them are actually in the buffer? Tackling one byte at a time, there is no problem serving this request, because as a byte is$õ, it may be fed again as input to the copy command. When the copy-from position makes it to the initial destination position, it is consequently fed data that was pasted from the beginning of$á. The operation is thus equivalent to the statement "copy the data you were given and repetitively paste it until it fits". As this type of pair repeats a single copy of$lmultiple times, it can be used to incorporate a flexible and easy form of run-length encoding.

Another way to see things is as follows: While encoding, for the search pointer to continue finding matched pairs past the end of$Ewindow, all characters from the first match at offset D and forward to the end of the search window must have matched input, and these are the (previously seen)$ïthat comprise a single run unit of length LR, which must equal D. Then as the search pointer proceeds past$!window and forward, as far as the run pattern repeats in the input, the search and input pointers will be in sync and match characters until$ois interrupted. Then L characters have been matched in total, L>D, and the code is [D,L,c].

Upon decoding [D,L,c], again, D=LR. When the first LR characters are read to the output, this corresponds to a single run unit appende$> buffer. At this point, the read pointer could be thought of as only needing to return int(L/LR) + (1 if L mod LR does not equal 0) times to the start of that single$•ed run unit, read LR characters (or maybe fewer on the last return), and repeat until a total of L$Nare read. But mirroring the encoding process, since the pattern is repetitive, the read pointer need only trail in sync with the write$/	by a fixed distance equal to the run length LR until L characters have been copied to output in total.

Considering the above, especially if the compression of data runs is expected to predominate, the window search should begin at the end of$-and proceed backwards, since run patterns, if they exist, will be found first and allow the search to terminate, absolutely if the current maximum matching sequence length is met, or judiciously, if a sufficient$/and finally for the simple possibility that the data is more recent and may correlate better with the next input.

Pseudocode[edit]
The p$	 is a reproduction of the LZ77 compression algorithm sliding window.

begin
     fill view from input
     while (view is not empty) do 
     $H     find longest prefix p of view starting in coded part
          i := position of p in window
          j := length of p
          X := first char after p in vie$Eoutput(i,j,X)
          add j+1 chars
     end
end
Example[edit]
The calculation of the LZ77-based factorization of the string aacaacabcabaaac illustrated.

The table shows t$l factorization using a dictionary buffer of size 12 and a preview$ 9. In the far right column is from top to bottom read the output of the algorithm (0, 0, "a") (1, 1, "c") (3, 4, "b") (3, 3$$	2, 3, "dollari"). The position is relative to the right edge of the dictionary buffer, this must be considered when decoding.

The buffers operate on the principle of a sliding window, i.e. to be compressed data stream is pushed right into t$q	. As noted in the algorithm, the shift is to the length of the match found in the dictionary, and a further position. This means that redundant triples be avoided as new characters are usually always taken individually$ê. In the example, so the third triple (0, 0, "c") should be incorporated, what the compression ratio, however, deteriorated significantly. The matches are green and marked to be moved string in red. It is important to note that more and$	 character is shifted, was found to be in accordance to new characters do not have to double encode.

Example of a LZ77 compression sliding window

The first popular$jis unknown, so that the first "a" is added to (0, 0, "a"). In the 2nd line "a" can already be read from the dictionary buffer (marked in green)$Ñ	"c" is accepted as the new character. In the 3rd line is a special case of the LZ77 algorithm can be seen$Zmatching string extends into the preview window, shown in the example by green text on a red background. Line 4 and 5 are equivalent to deal with the first two. Except that last a triple dollari is next inserted character, since the$öis fully compressed and there is no next character

Implementations[edit]
Even though all LZ77 algorithms work by definition on the same basic principle, they can vary widely in how they encode their$ødata to vary the numerical ranges of a length-distance pair, alter the number of bits consumed for a length-distance pair, and distinguish their length-distance pairs from literals (raw data encoded as itself, rather than as part$ƒ). A few examples:

The algorithm illustrated in Lempel and Ziv's original 1977 paper outputs all its data three values at a time: the length and distance of the longest match found in the buffer, and the literal which followed tha$?. If two successive characters in the input stream could only be encoded as literals, the length of the length-distance pair would be 0.
LZSS improves on LZ77 by using a 1 bit flag to indicate whether the next chunk of data is a literal or a$äce pair, and using literals if a length-distance pair would be longer.
In the PalmDoc format,$?is always encoded by a two-byte sequence. Of the 16 bits that make up these two bytes, 11 bits go to encoding the distance, 3$length, and the remaining two are used to make sure the decoder can identify the first byte as the beginning of such a two-byte sequence.
In the implementation used for many games by Electronic Arts,[6] the size in bytes of a $‚-distance pair can be specified inside the first byte of the length-distance pair itself; depending on if the first byte begins with a 0, 10, 110, or 111 (when read in big-endian bit orientation), the length of the entir$°can be 1 to 4 bytes large.
As of 2008, the most popular LZ77 based compression method is DEFLATE; it combines$6with Huffman coding.[7] Literals, lengths, and a symbol to indicate the end of the current block of data are all placed together into one alphabet. Distances can be safely placed into a separat$9
; since a dista$only occurs just after a length, it cannot be mistaken for another kind of symbol or vice versa.



